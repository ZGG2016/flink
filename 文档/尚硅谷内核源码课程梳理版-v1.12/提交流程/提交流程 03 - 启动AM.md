# 提交流程 03 - 启动AM

[TOC]

**版本:1.12**

-----------------------------------------------

程序通过 `env.execute()` 语句来触发程序执行，而在 `execute()` 方法中，创建 JobGraph 和 YarnClient, 然后开始部署集群，在部署中，程序在做必要检查后，开始启动 AM.

```java
public class YarnClusterDescriptor implements ClusterDescriptor<ApplicationId> {

	// This method will block until the ApplicationMaster/JobManager have been deployed on YARN.
	private ClusterClientProvider<ApplicationId> deployInternal(
			ClusterSpecification clusterSpecification,
			String applicationName,
			String yarnClusterEntrypoint,
			@Nullable JobGraph jobGraph,
			boolean detached) throws Exception {
		
		// 启动前检查
		...
		
		// 开始启动AM
		ApplicationReport report = startAppMaster(
				flinkConfiguration,
				applicationName,
				yarnClusterEntrypoint,  // 入口类名
				jobGraph,
				yarnClient,
				yarnApplication,
				validClusterSpecification);

		...
	}
}
```

## 1 startAppMaster

```java
	/** Lazily initialized list of files to ship. */
	private final List<File> shipFiles = new LinkedList<>();

	private ApplicationReport startAppMaster(
			Configuration configuration,
			String applicationName,
			String yarnClusterEntrypoint,  // 入口类名
			JobGraph jobGraph,
			YarnClient yarnClient,
			YarnClientApplication yarnApplication,
			ClusterSpecification clusterSpecification) throws Exception {

		// ------------------ Initialize the file systems -------------------------
		// 1. 初始化、创建 Hadoop 的 FileSystem
		org.apache.flink.core.fs.FileSystem.initialize(
				configuration,
				PluginUtils.createPluginManagerFromRootFolder(configuration));

		final FileSystem fs = FileSystem.get(yarnConfiguration);

		...

		ApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext();

		// 文件上传路径
		final List<Path> providedLibDirs = Utils.getQualifiedRemoteSharedPaths(configuration, yarnConfiguration);

		/* Yarn应用的文件上传器：FS、对应的HDFS路径
		* 	   用来上传：用户jar包、flink的依赖、flink的配置文件（接下来接近300行，不用看）
		* 	   直接跳到 fileUploader.close()
		* */

		final YarnApplicationFileUploader fileUploader = YarnApplicationFileUploader.from(
			fs,
			getStagingDir(fs),
			providedLibDirs,  // 对应的HDFS路径
			appContext.getApplicationId(),
			getFileReplication());

		// The files need to be shipped and added to classpath.
		// 2. 将要上传的文件添加到类路径
		Set<File> systemShipFiles = new HashSet<>(shipFiles.size());
		for (File file : shipFiles) {
			systemShipFiles.add(file.getAbsoluteFile());
		}

		// APPLICATION_LOG_CONFIG_FILE: conf目录下的log4j.properties
		final String logConfigFilePath = configuration.getString(YarnConfigOptionsInternal.APPLICATION_LOG_CONFIG_FILE);
		if (logConfigFilePath != null) {
			systemShipFiles.add(new File(logConfigFilePath));
		}

		// Set-up ApplicationSubmissionContext for the application
		final ApplicationId appId = appContext.getApplicationId();

		// ------------------ Add Zookeeper namespace to local flinkConfiguraton ------
		// 3. 将 zk 命名空间添加到本地flinkConfiguraton
		String zkNamespace = getZookeeperNamespace();
		// no user specified cli argument for namespace?

		// 如果没有取到，就使用 applicationId（YARN）
		if (zkNamespace == null || zkNamespace.isEmpty()) {
			// namespace defined in config? else use applicationId as default.
			// HA_CLUSTER_ID: flink 集群的id, 用来区分多个 flink 集群。
			//     如果是standalone需要设置，如果是 YARN(use applicationId) 和 Mesos，可以自动推断
			zkNamespace = configuration.getString(HighAvailabilityOptions.HA_CLUSTER_ID, String.valueOf(appId));
			setZookeeperNamespace(zkNamespace);
		}
		// 如果取到，就使用取到的
		configuration.setString(HighAvailabilityOptions.HA_CLUSTER_ID, zkNamespace);

		// 4. 高可用配置：重试次数，默认2次
		if (HighAvailabilityMode.isHighAvailabilityModeActivated(configuration)) {
			// activate re-execution of failed applications
			appContext.setMaxAppAttempts(
					configuration.getInteger(
							YarnConfigOptions.APPLICATION_ATTEMPTS.key(),
							YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS));

			activateHighAvailabilitySupport(appContext);
		} else {
			// set number of application retries to 1 in the default case
			appContext.setMaxAppAttempts(
					configuration.getInteger(
							YarnConfigOptions.APPLICATION_ATTEMPTS.key(),
							1));
		}

		// 5. 添加jar包
		final Set<Path> userJarFiles = new HashSet<>();
		if (jobGraph != null) {
			// jobGraph.getUserJars() [Set of JAR files required to run this job.]
			// 5.1 运行这个job所需的 jar 文件 （依赖的jar）
			userJarFiles.addAll(jobGraph.getUserJars().stream().map(f -> f.toUri()).map(Path::new).collect(Collectors.toSet()));
		}
		// PipelineOptions.JARS:A list of jar files that contain the user-defined function (UDF) classes and all classes used from within the UDFs.
		// 5.2 包含UDF类和UDF中使用的所有类的jar文件列表（用户打包的jar）
		final List<URI> jarUrls = ConfigUtils.decodeListFromConfig(configuration, PipelineOptions.JARS, URI::create);
		// 比较了入口类
		if (jarUrls != null && YarnApplicationClusterEntryPoint.class.getName().equals(yarnClusterEntrypoint)) {
			userJarFiles.addAll(jarUrls.stream().map(Path::new).collect(Collectors.toSet()));
		}

		// only for per job mode
		if (jobGraph != null) {
			// jobGraph.getUserArtifacts() [Set of custom files required to run this job.]
			// 5.3 运行这个job（在yarn per job模式下）所需的定制 jar 文件
			for (Map.Entry<String, DistributedCache.DistributedCacheEntry> entry : jobGraph.getUserArtifacts().entrySet()) {
				// only upload local files
				if (!Utils.isRemotePath(entry.getValue().filePath)) {
					Path localPath = new Path(entry.getValue().filePath);
					Tuple2<Path, Long> remoteFileInfo =
							fileUploader.uploadLocalFileToRemote(localPath, entry.getKey());
					jobGraph.setUserArtifactRemotePath(entry.getKey(), remoteFileInfo.f0.toString());
				}
			}

			jobGraph.writeUserArtifactEntriesToConfiguration();
		}

		if (providedLibDirs == null || providedLibDirs.isEmpty()) {
			// 将 flink lib 目录添加到 systemShipFiles 
			addLibFoldersToShipFiles(systemShipFiles);
		}


		// 6. 上传依赖文件（shipFiles 、 conf目录下的log4j.properties 、 flink lib 目录）
		// Register all files in provided lib dirs as local resources with public visibility
		// and upload the remaining dependencies as local resources with APPLICATION visibility.
		final List<String> systemClassPaths = fileUploader.registerProvidedLocalResources();
		final List<String> uploadedDependencies = fileUploader.registerMultipleLocalResources(
			// systemShipFiles 里现在包含 shipFiles 、 conf目录下的log4j.properties 、 flink lib 目录
			systemShipFiles.stream().map(e -> new Path(e.toURI())).collect(Collectors.toSet()),
			Path.CUR_DIR,
			LocalResourceType.FILE);
		systemClassPaths.addAll(uploadedDependencies);

		// 7. 上传文件（flink plugins 目录）
		// upload and register ship-only files
		// Plugin files only need to be shipped and should not be added to classpath.
		if (providedLibDirs == null || providedLibDirs.isEmpty()) {
			Set<File> shipOnlyFiles = new HashSet<>();
			// 将 flink plugins 目录添加到 shipOnlyFiles 
			addPluginsFoldersToShipFiles(shipOnlyFiles);
			fileUploader.registerMultipleLocalResources(
					shipOnlyFiles.stream().map(e -> new Path(e.toURI())).collect(Collectors.toSet()),
					Path.CUR_DIR,
					LocalResourceType.FILE);
		}

		if (!shipArchives.isEmpty()) {
			fileUploader.registerMultipleLocalResources(
				shipArchives.stream().map(e -> new Path(e.toURI())).collect(Collectors.toSet()),
				Path.CUR_DIR,
				LocalResourceType.ARCHIVE);
		}

		// 8. 上传用户jar包（依赖的jar）（用户打包的jar）（在yarn per job模式下）所需的定制 jar 文件
		// Upload and register user jars
		final List<String> userClassPaths = fileUploader.registerMultipleLocalResources(
			userJarFiles,
			userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED
					? ConfigConstants.DEFAULT_FLINK_USR_LIB_DIR
					: Path.CUR_DIR,
			LocalResourceType.FILE);

		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.ORDER) {
			systemClassPaths.addAll(userClassPaths);
		}

		// 9. normalize classpath by sorting
		Collections.sort(systemClassPaths);
		Collections.sort(userClassPaths);

		// classpath assembler
		// 10. 类路径集成：将 systemClassPaths 和 userClassPaths 都添加到 classPathBuilder
		StringBuilder classPathBuilder = new StringBuilder();
		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.FIRST) {
			for (String userClassPath : userClassPaths) {
				classPathBuilder.append(userClassPath).append(File.pathSeparator);
			}
		}
		for (String classPath : systemClassPaths) {
			classPathBuilder.append(classPath).append(File.pathSeparator);
		}

		// Setup jar for ApplicationMaster
		// 11. 将 flinkJarPath 和 userClassPaths 都添加到 classPathBuilder 
		// flinkJarPath 就是 flink lib 目录下的 flink-dist...jar 文件，用于使用 yarn 启动 flink job
		final YarnLocalResourceDescriptor localResourceDescFlinkJar = fileUploader.uploadFlinkDist(flinkJarPath);
		classPathBuilder.append(localResourceDescFlinkJar.getResourceKey()).append(File.pathSeparator);


		// 12. write job graph to tmp file and add it to local resource
		// TODO: server use user main method to generate job graph
		...

	
		// 13. 上传Flink的配置文件 - flink-conf.yaml
		// Upload the flink configuration
		// write out configuration file
		File tmpConfigurationFile = null;
		try {
			tmpConfigurationFile = File.createTempFile(appId + "-flink-conf.yaml", null);
			BootstrapTools.writeConfiguration(configuration, tmpConfigurationFile);

			String flinkConfigKey = "flink-conf.yaml";
			fileUploader.registerSingleLocalResource(
				flinkConfigKey,
				new Path(tmpConfigurationFile.getAbsolutePath()),
				"",
				LocalResourceType.FILE,
				true,
				true);
			classPathBuilder.append("flink-conf.yaml").append(File.pathSeparator);
		}...

		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.LAST) {
			for (String userClassPath : userClassPaths) {
				classPathBuilder.append(userClassPath).append(File.pathSeparator);
			}
		}
		// To support Yarn Secure Integration Test Scenario
		...

		// 14. jobmanager内存配置
		// 最后 new 了一个 JobManagerProcessSpec （包含JVM Heap Memory   Off-heap Memory  JVM Metaspace  JVM Overhead）
		final JobManagerProcessSpec processSpec = JobManagerProcessUtils.processSpecFromConfigWithNewOptionToInterpretLegacyHeap(
			flinkConfiguration,
			JobManagerOptions.TOTAL_PROCESS_MEMORY);
		// 15. 创建 amContainer(1.1节)
		final ContainerLaunchContext amContainer = setupApplicationMasterContainer(
				yarnClusterEntrypoint,
				hasKrb5,
				processSpec);

		...

		// 16. 将上面注册的所有文件信息都给 amContainer
		amContainer.setLocalResources(fileUploader.getRegisteredLocalResources());
		fileUploader.close();

		// Setup CLASSPATH and environment variables for ApplicationMaster
		// 17. 创建Map，用来存储 AM 依赖的环境变量和类路径
		final Map<String, String> appMasterEnv = new HashMap<>();
		// set user specified app master environment variables
		appMasterEnv.putAll(
			ConfigurationUtils.getPrefixedKeyValuePairs(ResourceManagerOptions.CONTAINERIZED_MASTER_ENV_PREFIX, configuration));
		// set Flink app class path
		appMasterEnv.put(YarnConfigKeys.ENV_FLINK_CLASSPATH, classPathBuilder.toString());

		// set Flink on YARN internal configuration values
		appMasterEnv.put(YarnConfigKeys.FLINK_DIST_JAR, localResourceDescFlinkJar.toString());
		appMasterEnv.put(YarnConfigKeys.ENV_APP_ID, appId.toString());
		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_HOME_DIR, fileUploader.getHomeDir().toString());
		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_SHIP_FILES, encodeYarnLocalResourceDescriptorListToString(fileUploader.getEnvShipResourceList()));
		appMasterEnv.put(YarnConfigKeys.ENV_ZOOKEEPER_NAMESPACE, getZookeeperNamespace());
		appMasterEnv.put(YarnConfigKeys.FLINK_YARN_FILES, fileUploader.getApplicationDir().toUri().toString());

		// https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site/src/site/markdown/YarnApplicationSecurity.md#identity-on-an-insecure-cluster-hadoop_user_name
		appMasterEnv.put(YarnConfigKeys.ENV_HADOOP_USER_NAME, UserGroupInformation.getCurrentUser().getUserName());

		...  

		// set classpath from YARN configuration
		Utils.setupYarnClassPath(yarnConfiguration, appMasterEnv);

		/*
		 * 18. 将之前封装的 Map（AM依赖的环境信息、类路径），设置到容器里  （此时，amContainer就有执行job各种文件）
		 */ 
		amContainer.setEnvironment(appMasterEnv);

		// Set up resource type requirements for ApplicationMaster
		// ApplicationMaster所需的资源容量
		Resource capability = Records.newRecord(Resource.class);
		capability.setMemory(clusterSpecification.getMasterMemoryMB());
		capability.setVirtualCores(flinkConfiguration.getInteger(YarnConfigOptions.APP_MASTER_VCORES));

		final String customApplicationName = customName != null ? customName : applicationName;

		// 19. 设置应用程序提交的上下文
		appContext.setApplicationName(customApplicationName);
		appContext.setApplicationType(applicationType != null ? applicationType : "Apache Flink");
		appContext.setAMContainerSpec(amContainer);
		appContext.setResource(capability);

		// Set priority for application 应用程序优先级
		int priorityNum = flinkConfiguration.getInteger(YarnConfigOptions.APPLICATION_PRIORITY);
		if (priorityNum >= 0) {
			Priority priority = Priority.newInstance(priorityNum);
			appContext.setPriority(priority);
		}

		if (yarnQueue != null) {
			appContext.setQueue(yarnQueue);
		}

		...

		// 20. 将Application提交给yarn
		// appContext里有 yarnQueue、应用程序priority、ApplicationMaster所需的资源容量、
		//     封装了AM的环境信息和类路径的amContainer、应用程序类型、应用程序名称
		yarnClient.submitApplication(appContext);

		LOG.info("Waiting for the cluster to be allocated");
		...
		return report;

		// 所以，总的来说，
		// 在 `startAppMaster()` 方法中，
		// 1. 会将各种 jar 文件和依赖上传到 hdfs; 
		// 2. 创建 amContainer, 其中包含 am 的启动命令, 和 am 依赖的环境变量和类路径等; 
		// 3. 创建 appContext 用来提交应用程序。
		// 执行完 `startAppMaster()` 方法后，启动了 am 进程; 应用程序被提交给了 yarn 的rm。
	}
```

### 1.1 setupApplicationMasterContainer

创建 amContainer，其中确定了 am 的启动命令，并指定了启动入口类

```java
	ContainerLaunchContext setupApplicationMasterContainer(
			String yarnClusterEntrypoint,  // 入口类名
			boolean hasKrb5,
			JobManagerProcessSpec processSpec) {
		// ------------------ Prepare Application Master Container  ------------------------------

		// respect custom JVM options in the YAML file
		String javaOpts = flinkConfiguration.getString(CoreOptions.FLINK_JVM_OPTIONS);
		if (flinkConfiguration.getString(CoreOptions.FLINK_JM_JVM_OPTIONS).length() > 0) {
			javaOpts += " " + flinkConfiguration.getString(CoreOptions.FLINK_JM_JVM_OPTIONS);
		}

		//krb5.conf file will be available as local resource in JM/TM container
		if (hasKrb5) {
			javaOpts += " -Djava.security.krb5.conf=krb5.conf";
		}

		// Set up the container launch context for the application master
		ContainerLaunchContext amContainer = Records.newRecord(ContainerLaunchContext.class);

		final  Map<String, String> startCommandValues = new HashMap<>();
		startCommandValues.put("java", "$JAVA_HOME/bin/java");

		String jvmHeapMem = JobManagerProcessUtils.generateJvmParametersStr(processSpec, flinkConfiguration);
		startCommandValues.put("jvmmem", jvmHeapMem);

		startCommandValues.put("jvmopts", javaOpts);
		startCommandValues.put("logging", YarnLogConfigUtil.getLoggingYarnCommand(flinkConfiguration));

		// 指定了 am 启动入口类
		startCommandValues.put("class", yarnClusterEntrypoint);
		startCommandValues.put("redirects",
			"1> " + ApplicationConstants.LOG_DIR_EXPANSION_VAR + "/jobmanager.out " +
			"2> " + ApplicationConstants.LOG_DIR_EXPANSION_VAR + "/jobmanager.err");
		String dynamicParameterListStr = JobManagerProcessUtils.generateDynamicConfigsStr(processSpec);
		startCommandValues.put("args", dynamicParameterListStr);

		final String commandTemplate = flinkConfiguration
				.getString(ConfigConstants.YARN_CONTAINER_START_COMMAND_TEMPLATE,
						ConfigConstants.DEFAULT_YARN_CONTAINER_START_COMMAND_TEMPLATE);
		final String amCommand =
			BootstrapTools.getStartCommand(commandTemplate, startCommandValues);
		// 确定了 am 的启动命令
		amContainer.setCommands(Collections.singletonList(amCommand));

		LOG.debug("Application Master start command: " + amCommand);

		return amContainer;
	}
```

### 1.2 submitApplication(appContext)

`submitApplication` 方法是抽象类 YarnClient 中的方法，这里查看其子类 `YarnClientImpl` 中的方法。

```java
package org.apache.hadoop.yarn.client.api.impl;

public class YarnClientImpl extends YarnClient {

	// The protocol between clients and the <code>ResourceManager</code> to submit/abort jobs and to get information on applications, cluster metrics, nodes, queues and ACLs
	// 客户端和RM间提交/中止jobs的协议
	protected ApplicationClientProtocol rmClient;

	public ApplicationId submitApplication(ApplicationSubmissionContext appContext)
          throws YarnException, IOException {

    ApplicationId applicationId = appContext.getApplicationId();
    ...

    // 这个请求是客户端给RM发送提交应用程序的请求
    // SubmitApplicationRequest: The request sent by a client to <em>submit an application</em> to the  ResourceManager
    SubmitApplicationRequest request =
        Records.newRecord(SubmitApplicationRequest.class);
    // 请求里包含提交上下文信息
    request.setApplicationSubmissionContext(appContext);

    //TODO: YARN-1763:Handle RM failovers during the submitApplication call.
    // 提交应用程序
    rmClient.submitApplication(request);

    int pollCount = 0;
    long startTime = System.currentTimeMillis();

    // 提交后状态的监控等
    while (true) {
      try {
        YarnApplicationState state =
            getApplicationReport(applicationId).getYarnApplicationState();
        if (!state.equals(YarnApplicationState.NEW) &&
            !state.equals(YarnApplicationState.NEW_SAVING)) {
          LOG.info("Submitted application " + applicationId);
          break;
        }

        long elapsedMillis = System.currentTimeMillis() - startTime;
        if (enforceAsyncAPITimeout() &&
            elapsedMillis >= asyncApiPollTimeoutMillis) {
          throw new YarnException("Timed out while waiting for application " +
              applicationId + " to be submitted successfully");
        }

        // Notify the client through the log every 10 poll, in case the client
        // is blocked here too long.
        if (++pollCount % 10 == 0) {
          LOG.info("Application submission is not finished, " +
              "submitted application " + applicationId +
              " is still in " + state);
        }
        try {
          Thread.sleep(submitPollIntervalMillis);
        } catch (InterruptedException ie) {
          LOG.error("Interrupted while waiting for application "
              + applicationId
              + " to be successfully submitted.");
        }
      } catch (ApplicationNotFoundException ex) {
        // FailOver or RM restart happens before RMStateStore saves
        // ApplicationState
        LOG.info("Re-submit application " + applicationId + "with the " +
            "same ApplicationSubmissionContext");
        rmClient.submitApplication(request);
      }
    }

    return applicationId;
  }

}
```